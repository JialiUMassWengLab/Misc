{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477c07d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/efs/home/iet5740/Projects/UKBPPP/torch_venv/lib64/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca20058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 1.15k/1.15k [00:00<00:00, 226kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.63G/1.63G [00:03<00:00, 447MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 7.31kB/s]\n",
      "Downloading vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.63MB/s]\n",
      "Downloading merges.txt: 100%|██████████| 456k/456k [00:03<00:00, 126kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 34.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0239238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5036356449127197,\n",
       "  0.47879964113235474,\n",
       "  0.012600167654454708,\n",
       "  0.002655783900991082,\n",
       "  0.0023087572772055864]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268f1d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 385/385 [00:00<00:00, 365kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 440M/440M [00:01<00:00, 390MB/s] \n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 28.0kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 226k/226k [00:00<00:00, 10.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"fill-mask\", model=\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba8b0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.28550955653190613,\n",
       "  'token': 5105,\n",
       "  'token_str': 'p53',\n",
       "  'sequence': 'p53 is a tumor suppressor gene.'},\n",
       " {'score': 0.16949503123760223,\n",
       "  'token': 13544,\n",
       "  'token_str': 'tp53',\n",
       "  'sequence': 'tp53 is a tumor suppressor gene.'},\n",
       " {'score': 0.0856199562549591,\n",
       "  'token': 11779,\n",
       "  'token_str': 'brca1',\n",
       "  'sequence': 'brca1 is a tumor suppressor gene.'},\n",
       " {'score': 0.07339830696582794,\n",
       "  'token': 9496,\n",
       "  'token_str': 'pten',\n",
       "  'sequence': 'pten is a tumor suppressor gene.'},\n",
       " {'score': 0.06466539949178696,\n",
       "  'token': 2176,\n",
       "  'token_str': 'it',\n",
       "  'sequence': 'it is a tumor suppressor gene.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"[MASK] is a tumor suppressor gene.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcdbcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.14128601551055908,\n",
       "  'token': 4531,\n",
       "  'token_str': 'inflammation',\n",
       "  'sequence': 'inflammation is implicated in type - 2 diabetes.'},\n",
       " {'score': 0.11703887581825256,\n",
       "  'token': 5379,\n",
       "  'token_str': 'obesity',\n",
       "  'sequence': 'obesity is implicated in type - 2 diabetes.'},\n",
       " {'score': 0.06760377436876297,\n",
       "  'token': 9598,\n",
       "  'token_str': 'leptin',\n",
       "  'sequence': 'leptin is implicated in type - 2 diabetes.'},\n",
       " {'score': 0.04628118872642517,\n",
       "  'token': 29587,\n",
       "  'token_str': 'hyperinsulinemia',\n",
       "  'sequence': 'hyperinsulinemia is implicated in type - 2 diabetes.'},\n",
       " {'score': 0.03999573364853859,\n",
       "  'token': 2176,\n",
       "  'token_str': 'it',\n",
       "  'sequence': 'it is implicated in type - 2 diabetes.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"[MASK] is implicated in type-2 diabetes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236c776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/efs/home/iet5740/Projects/UKBPPP/torch_venv/lib64/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b4347a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa5a576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000000000000019884624838656"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f411fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12055bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"[MASK] is a causal gene for Inflammatory Bowel Disease.\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade3de74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    4, 1977,   43, 9263, 2359, 1958, 3769, 9472, 2573,   18,    3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9247d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.sep_token_id)\n",
    "print(tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cedc1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ac848c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids == tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04e61e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beef51ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.5259,  2.0390, -4.7685,  ...,  6.4460, -4.4976,  0.9217]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0, mask_token_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e35b4d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits[0,mask_token_index][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe17d728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nod2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "tokenizer.decode(predicted_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0977e0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nod2\n",
      "it\n",
      "tnf\n",
      "il10\n",
      "tlr4\n",
      "foxp3\n",
      "fto\n",
      "apc\n",
      "stat3\n",
      "ctla4\n"
     ]
    }
   ],
   "source": [
    "sorted_tensor = torch.topk(logits[0,mask_token_index][0],10).indices\n",
    "for i in range(10):\n",
    "    print(tokenizer.decode(sorted_tensor[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19d33d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('bert',\n",
       "               BertModel(\n",
       "                 (embeddings): BertEmbeddings(\n",
       "                   (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "                   (position_embeddings): Embedding(512, 768)\n",
       "                   (token_type_embeddings): Embedding(2, 768)\n",
       "                   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                   (dropout): Dropout(p=0.1, inplace=False)\n",
       "                 )\n",
       "                 (encoder): BertEncoder(\n",
       "                   (layer): ModuleList(\n",
       "                     (0): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (1): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (2): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (3): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (4): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (5): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (6): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (7): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (8): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (9): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (10): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                     (11): BertLayer(\n",
       "                       (attention): BertAttention(\n",
       "                         (self): BertSelfAttention(\n",
       "                           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                         (output): BertSelfOutput(\n",
       "                           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                           (dropout): Dropout(p=0.1, inplace=False)\n",
       "                         )\n",
       "                       )\n",
       "                       (intermediate): BertIntermediate(\n",
       "                         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                         (intermediate_act_fn): GELUActivation()\n",
       "                       )\n",
       "                       (output): BertOutput(\n",
       "                         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                         (dropout): Dropout(p=0.1, inplace=False)\n",
       "                       )\n",
       "                     )\n",
       "                   )\n",
       "                 )\n",
       "               )),\n",
       "              ('cls',\n",
       "               BertOnlyMLMHead(\n",
       "                 (predictions): BertLMPredictionHead(\n",
       "                   (transform): BertPredictionHeadTransform(\n",
       "                     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                     (transform_act_fn): GELUActivation()\n",
       "                     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                   )\n",
       "                   (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "                 )\n",
       "               ))]),\n",
       " 'config': BertConfig {\n",
       "   \"_name_or_path\": \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\",\n",
       "   \"architectures\": [\n",
       "     \"BertForMaskedLM\"\n",
       "   ],\n",
       "   \"attention_probs_dropout_prob\": 0.1,\n",
       "   \"classifier_dropout\": null,\n",
       "   \"hidden_act\": \"gelu\",\n",
       "   \"hidden_dropout_prob\": 0.1,\n",
       "   \"hidden_size\": 768,\n",
       "   \"initializer_range\": 0.02,\n",
       "   \"intermediate_size\": 3072,\n",
       "   \"layer_norm_eps\": 1e-12,\n",
       "   \"max_position_embeddings\": 512,\n",
       "   \"model_type\": \"bert\",\n",
       "   \"num_attention_heads\": 12,\n",
       "   \"num_hidden_layers\": 12,\n",
       "   \"pad_token_id\": 0,\n",
       "   \"position_embedding_type\": \"absolute\",\n",
       "   \"transformers_version\": \"4.30.2\",\n",
       "   \"type_vocab_size\": 2,\n",
       "   \"use_cache\": true,\n",
       "   \"vocab_size\": 30522\n",
       " },\n",
       " 'name_or_path': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext',\n",
       " 'warnings_issued': {},\n",
       " 'generation_config': GenerationConfig {\n",
       "   \"_from_model_config\": true,\n",
       "   \"pad_token_id\": 0,\n",
       "   \"transformers_version\": \"4.30.2\"\n",
       " },\n",
       " '_is_hf_initialized': True,\n",
       " 'is_loaded_in_4bit': False,\n",
       " 'is_loaded_in_8bit': False,\n",
       " 'is_quantized': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22b22a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings = model(**inputs, output_hidden_states=True).hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56516c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c2de417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n",
      "torch.Size([1, 12, 768])\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(embeddings):\n",
    "    print(layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "906cf799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1079,  0.2989,  0.0111,  ...,  0.1501,  0.0076,  0.0868],\n",
       "        [-0.1667, -0.2235, -0.0414,  ...,  0.2386, -0.0464, -0.1347],\n",
       "        [-0.0484,  0.5851,  0.4326,  ...,  0.1765, -0.0968,  0.6698],\n",
       "        ...,\n",
       "        [-0.1578, -0.0203,  0.1617,  ..., -0.2010, -0.4561,  0.5157],\n",
       "        [ 0.0249,  0.4300, -0.1002,  ..., -0.2891,  0.1824,  0.5265],\n",
       "        [ 0.1931,  0.2004, -0.4961,  ..., -0.0038,  0.1135,  0.5273]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef8344c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1726, -0.6324, -0.0109,  ..., -0.2206,  0.8523,  0.1826],\n",
       "        [-0.1518, -0.3321,  0.1190,  ..., -0.0778,  0.2135, -0.0367],\n",
       "        [-0.1118, -0.2569,  0.0689,  ..., -0.1819, -0.0332,  0.2606],\n",
       "        ...,\n",
       "        [ 0.1249,  0.1328,  0.1745,  ..., -0.3186, -0.0856,  0.4124],\n",
       "        [-0.1887, -0.2955, -0.0451,  ..., -0.1536,  0.2173,  0.1748],\n",
       "        [-0.1887, -0.2954, -0.0451,  ..., -0.1535,  0.2173,  0.1747]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45e81d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = tokenizer(\"[MASK] is a causal gene for IBD.\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    embeddings2 = model(**inputs2, output_hidden_states=True).hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a86b154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1079,  0.2989,  0.0111,  ...,  0.1501,  0.0076,  0.0868],\n",
       "        [-0.1667, -0.2235, -0.0414,  ...,  0.2386, -0.0464, -0.1347],\n",
       "        [-0.0484,  0.5851,  0.4326,  ...,  0.1765, -0.0968,  0.6698],\n",
       "        ...,\n",
       "        [-0.2087,  0.2629,  0.4794,  ..., -0.2845,  0.1548,  0.4426],\n",
       "        [ 0.0414,  0.4427,  0.0579,  ..., -0.1193,  0.0763,  0.4232],\n",
       "        [ 0.1203,  0.1681, -0.2495,  ...,  0.0127,  0.0307,  0.5334]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f198f8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4288e-01, -6.1786e-01,  1.1789e-01,  ..., -3.7112e-01,\n",
       "          8.1703e-01,  3.8267e-02],\n",
       "        [-2.4988e-01, -3.8653e-01,  1.6087e-01,  ..., -1.4411e-01,\n",
       "          2.0424e-01, -9.3418e-02],\n",
       "        [-1.0311e-01, -2.7191e-01,  8.3761e-02,  ..., -2.1988e-01,\n",
       "         -5.2022e-02,  2.4860e-01],\n",
       "        ...,\n",
       "        [-1.2637e-01, -1.3083e-01,  1.0110e-04,  ..., -2.6098e-01,\n",
       "          4.3356e-01,  6.3144e-02],\n",
       "        [-1.7639e-01, -3.1500e-01,  5.4075e-03,  ..., -2.0239e-01,\n",
       "          2.6251e-01,  1.0453e-01],\n",
       "        [-1.7639e-01, -3.1489e-01,  5.4220e-03,  ..., -2.0232e-01,\n",
       "          2.6252e-01,  1.0445e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings2[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "837f70b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(embeddings[0][0][0] == embeddings2[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d125405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(embeddings[0][0][1] == embeddings2[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec35e43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(embeddings[0][0][2] == embeddings2[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf80b057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(embeddings[0][0][3] == embeddings2[0][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d59b5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(embeddings[0][0][4] == embeddings2[0][0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e2ecb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(embeddings[0][0][5] == embeddings2[0][0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "466ea8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(embeddings[0][0][6] == embeddings2[0][0][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25620a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(embeddings[0][0][7] == embeddings2[0][0][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33738d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(embeddings[0][0][8] == embeddings2[0][0][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a59ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs3 = tokenizer(\"A rapid heartrate that exceeds the range of the normal resting heartrate for age.\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    embeddings3 = model(**inputs3, output_hidden_states=True).hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ccc7b146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3074, -0.1327,  0.0125,  ..., -0.4887,  0.1633,  0.2599],\n",
       "        [-0.0959, -0.0583, -0.2491,  ..., -0.1717, -0.0475,  0.3064],\n",
       "        [-0.2508,  0.0943, -0.4464,  ..., -0.2531, -0.8193,  0.1961],\n",
       "        ...,\n",
       "        [-0.3938, -0.1992, -0.3423,  ..., -0.2177, -0.0013,  0.0479],\n",
       "        [-0.2669, -0.0567, -0.1716,  ..., -0.3587,  0.1777,  0.1864],\n",
       "        [-0.2669, -0.0566, -0.1716,  ..., -0.3586,  0.1777,  0.1864]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings3[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0485753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs4 = tokenizer(\"[CLS] Abnormal mitochondrial morphology\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    embeddings4 = model(**inputs4, output_hidden_states=True).hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1fcfc7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1079,  0.2989,  0.0111,  ...,  0.1501,  0.0076,  0.0868],\n",
       "        [-0.3680, -0.1059,  0.0015,  ...,  0.2894, -0.0268, -0.0391],\n",
       "        [-0.0907, -0.1663, -0.3307,  ...,  0.1273, -0.5079, -0.1308],\n",
       "        [ 0.5174, -0.3276, -0.3643,  ...,  0.0572, -0.6786,  0.4968],\n",
       "        [-0.0858, -0.2374,  0.5178,  ...,  0.3518, -0.5319, -0.3129],\n",
       "        [ 0.0472, -0.0933, -0.2096,  ...,  0.1460,  0.0254,  0.3831]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings4[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c1a58b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3730, -0.2231,  0.2971,  ..., -0.4035,  0.6624,  0.2740],\n",
       "        [-0.3376, -0.1456,  0.5041,  ..., -0.2092,  0.2891,  0.1060],\n",
       "        [-0.2214,  0.0038,  0.0025,  ..., -0.2787,  0.2070,  0.2588],\n",
       "        [-0.1624, -0.0490,  0.2448,  ..., -0.0849, -0.1461,  0.1211],\n",
       "        [-0.0432,  0.3704, -0.2316,  ..., -0.3551,  1.2227,  0.3730],\n",
       "        [-0.2283, -0.1214,  0.0477,  ..., -0.1214,  0.1604,  0.0383]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings4[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5effe91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_tokenizer': <tokenizers.Tokenizer at 0x5ce81720>,\n",
       " '_decode_use_source_tokenizer': False,\n",
       " 'init_inputs': (),\n",
       " 'init_kwargs': {'do_lower_case': True,\n",
       "  'unk_token': '[UNK]',\n",
       "  'sep_token': '[SEP]',\n",
       "  'pad_token': '[PAD]',\n",
       "  'cls_token': '[CLS]',\n",
       "  'mask_token': '[MASK]',\n",
       "  'tokenize_chinese_chars': True,\n",
       "  'strip_accents': None,\n",
       "  'special_tokens_map_file': None,\n",
       "  'name_or_path': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext',\n",
       "  'do_basic_tokenize': True,\n",
       "  'never_split': None,\n",
       "  'tokenizer_file': None},\n",
       " 'name_or_path': 'microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext',\n",
       " '_processor_class': None,\n",
       " 'model_max_length': 1000000000000000019884624838656,\n",
       " 'padding_side': 'right',\n",
       " 'truncation_side': 'right',\n",
       " 'model_input_names': ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       " 'clean_up_tokenization_spaces': True,\n",
       " 'deprecation_warnings': {},\n",
       " '_in_target_context_manager': False,\n",
       " '_bos_token': None,\n",
       " '_eos_token': None,\n",
       " '_unk_token': '[UNK]',\n",
       " '_sep_token': '[SEP]',\n",
       " '_pad_token': '[PAD]',\n",
       " '_cls_token': '[CLS]',\n",
       " '_mask_token': '[MASK]',\n",
       " '_pad_token_type_id': 0,\n",
       " '_additional_special_tokens': [],\n",
       " 'verbose': True,\n",
       " 'do_lower_case': True}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfac11c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2,    2, 4552, 4596, 6076,    3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eb69c111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 14311,  1927,  1920,  5321,  2433,     3],\n",
       "        [    2, 14311,  1990,  5352,  2347,  4213,     3],\n",
       "        [    2,  4552,  2024,  4031,     3,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0]])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [\"Abnormality of the cardiovascular system\",\"Abnormality on pulmonary function testing\",\"Abnormal cell proliferation\"]\n",
    "inputs5 = tokenizer(input_list, return_tensors=\"pt\",padding=True)\n",
    "inputs5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ddc1b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings5 = model(**inputs5, output_hidden_states=True).hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b0d0023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 768])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings5[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa5550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "torch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
